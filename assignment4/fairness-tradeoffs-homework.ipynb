{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework: Fair prediction\n",
    "\n",
    "In this homework you will build a logistic regression classifier on the Machine Bias data, then tune it to get equal false positive rates between black and white defendants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0. Loading the data and building the feature matrix.\n",
    "Free code, copied from our class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select between data on overall arrests and arrests for violent crimes\n",
    "# This allows quick comparisons of the difference between these two data sets\n",
    "violent = False\n",
    "\n",
    "if violent:\n",
    "    fname ='compas-scores-two-years-violent.csv'\n",
    "    decile_col = 'v_decile_score'\n",
    "    score_col = 'v_score_text'\n",
    "else:\n",
    "    fname ='compas-scores-two-years.csv'\n",
    "    decile_col = 'decile_score'\n",
    "    score_col = 'score_text'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6172, 53)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning ala ProPublica\n",
    "cv = cv[\n",
    "    (cv.days_b_screening_arrest <= 30) &  \n",
    "    (cv.days_b_screening_arrest >= -30) &  \n",
    "    (cv.is_recid != -1) &\n",
    "    (cv.c_charge_degree != 'O') &\n",
    "    (cv[score_col] != 'N/A')\n",
    "]\n",
    "\n",
    "# Keep only black and white races for this analysis\n",
    "# cv = cv[(cv.race == 'African-American') | (cv.race=='Caucasian')]\n",
    "         \n",
    "# renumber the rows from 0 again\n",
    "cv.reset_index(inplace=True, drop=True) \n",
    "cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up dummy variables for age, race, gender\n",
    "features = pd.concat(\n",
    "    [pd.get_dummies(cv.age_cat, prefix='age'),\n",
    "     pd.get_dummies(cv.sex, prefix='sex'),\n",
    "     pd.get_dummies(cv.c_charge_degree, prefix='degree'), # felony or misdemeanor charge ('f' or 'm')\n",
    "     cv.priors_count],\n",
    "    axis=1)\n",
    "\n",
    "# We should have one less dummy variable than the number of categories, to avoid the \"dummy variable trap\"\n",
    "# See https://www.quora.com/When-do-I-fall-in-the-dummy-variable-trap\n",
    "features.drop(['age_25 - 45', 'sex_Female', 'degree_M'], axis=1, inplace=True)\n",
    "\n",
    "# Try to predict whether someone is re-arrested\n",
    "target = cv.two_year_recid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Your basic logistic regression\n",
    "\n",
    "Fit a logistic regression to this data. Print out the accuracy, PPV, and FPV overall, and for just black vs. white defendants. \n",
    "\n",
    "Most of the code you need can be found in the class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a logistic regression\n",
    "x = features.values\n",
    "y = target.values\n",
    "rez = []\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the result on the training data\n",
    "y_pred = lr.predict(x)\n",
    "guessed=pd.Series(y_pred)==1\n",
    "# print(guessed)\n",
    "actual=cv.two_year_recid==1\n",
    "\n",
    "cm = pd.crosstab(guessed, actual, rownames=['guessed'], colnames=['actual'])\n",
    "# cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free code for you!\n",
    "\n",
    "# cm is a confusion matrix. The rows are guessed, the columns are actual \n",
    "def print_ppv_fpv(cm):\n",
    "    # the indices here are [col][row] or [actual][guessed]\n",
    "    TN = cm[False][False]   \n",
    "    TP = cm[True][True]\n",
    "    FN = cm[True][False]\n",
    "    FP = cm[False][True]\n",
    "    print('Accuracy: ', (TN+TP)/(TN+TP+FN+FP))\n",
    "    print('PPV: ', TP / (TP + FP))\n",
    "    print('FPR: ', FP / (FP + TN))\n",
    "    print('FNR: ', FN / (FN + TP))\n",
    "    print()\n",
    "#     return (FP / (FP + TN))\n",
    "\n",
    "def print_metrics(guessed, actual):\n",
    "    cm = pd.crosstab(guessed, actual, rownames=['guessed'], colnames=['actual'])\n",
    "    print(cm)\n",
    "    print()\n",
    "    print_ppv_fpv(cm)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everyone\n",
      "Accuracy:  0.670447180816591\n",
      "PPV:  0.6638477801268499\n",
      "FPR:  0.23639607493309545\n",
      "FNR:  0.4410822356710573\n",
      "\n",
      "White defendents\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     1068    494\n",
      "True       213    328\n",
      "\n",
      "Accuracy:  0.6638135996195911\n",
      "PPV:  0.6062846580406654\n",
      "FPR:  0.16627634660421545\n",
      "FNR:  0.6009732360097324\n",
      "\n",
      "Black defendents\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     1026    564\n",
      "True       488   1097\n",
      "\n",
      "Accuracy:  0.6686614173228347\n",
      "PPV:  0.6921135646687697\n",
      "FPR:  0.32232496697490093\n",
      "FNR:  0.3395544852498495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy, PPV, FPV, FNV for\n",
    "#  - everyone\n",
    "print(\"Everyone\")\n",
    "print_ppv_fpv(cm)\n",
    "#  - just white defendants\n",
    "print(\"White defendents\")\n",
    "white_def = cv.race == 'Caucasian'\n",
    "print_metrics(guessed[white_def], actual[white_def])\n",
    "#  - just black defendants\n",
    "print(\"Black defendents\")\n",
    "black_def = cv.race == 'African-American'\n",
    "print_metrics(guessed[black_def], actual[black_def])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Equalizing false positive rates\n",
    "Now you'll build your own classifier that equalizes the false positive rates between white and non-white defendants. There are many ways to do this. We're going to use race explicitly to set a different threshold for white and black defendants. \n",
    "\n",
    "To begin with, we are going to write our own prediction function, starting with this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a trained LogisticRegression, a set of features, and a threshold\n",
    "# Predicts true wherever the regression gives a probability > threshold\n",
    "# Note: returns a numpy array, not a dataframe\n",
    "def predict_threshold(classifier, features, threshold):\n",
    "    # predict_proba returns two columns: probability of true, and probability of false\n",
    "    # [:,1] selects the second column\n",
    "    rez = classifier.predict_proba(features)[:,1]\n",
    "    return classifier.predict_proba(features)[:,1] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True ... False False  True]\n"
     ]
    }
   ],
   "source": [
    "# This is the same as lr.predict(x) when we use a threshold of 0.5\n",
    "y_pred2 = predict_threshold(lr, x, 0.5)\n",
    "print(y_pred2)\n",
    "\n",
    "guessed2=pd.Series(y_pred2)==1\n",
    "actual=cv.two_year_recid==1\n",
    "cm = pd.crosstab(guessed2, actual, rownames=['guessed'], colnames=['actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adapt this function so it takes two thresholds `a_threshold` and `b_threshold`, and a column of values `use_b` which means use the `b_threshold` for any row where it's true. The idea is to allow us to adjust the thresholds independently on two different groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function which takes the following arguments\n",
    "def predict_threshold_groups(classifier, features, a_threshold, b_threshold, use_b):\n",
    "    # calculate probabilities from our classifier\n",
    "    \n",
    "    # Create one Series which is True where the probabilities are bigger than a_threshold, \n",
    "    # and another for b_threshold\n",
    "    # Then combine them, selecting values from either Series according to use_b\n",
    "    a_result = predict_threshold(classifier, features, a_threshold)\n",
    "    b_result = predict_threshold(classifier, features, b_threshold)\n",
    "    final_threshold = []\n",
    "    for i in range(0, len(use_b)):\n",
    "        if use_b[i]:\n",
    "            final_threshold.append(b_result[i])\n",
    "        else:\n",
    "            final_threshold.append(a_result[i])\n",
    "    return final_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this function with different thresholds for black and white defendants. Print out the confusion martrix, accuracy, FPV, and PPV for the results -- again, overall and for each race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everyone\n",
      "Accuracy:  0.670447180816591\n",
      "PPV:  0.6638477801268499\n",
      "FPR:  0.23639607493309545\n",
      "FNR:  0.4410822356710573\n",
      "\n",
      "White defendents\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     1068    494\n",
      "True       213    328\n",
      "\n",
      "Accuracy:  0.6638135996195911\n",
      "PPV:  0.6062846580406654\n",
      "FPR:  0.16627634660421545\n",
      "FNR:  0.6009732360097324\n",
      "\n",
      "Black defendents\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     1026    564\n",
      "True       488   1097\n",
      "\n",
      "Accuracy:  0.6686614173228347\n",
      "PPV:  0.6921135646687697\n",
      "FPR:  0.32232496697490093\n",
      "FNR:  0.3395544852498495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict recidivism with different thresholds for black and white\n",
    "# Print out metrics for everyone, black, and white\n",
    "y_pred3 = predict_threshold_groups(lr, x, 0.5, 0.5, black_def)\n",
    "# print(y_pred3)\n",
    "\n",
    "guessed3=pd.Series(y_pred3)==1\n",
    "actual=cv.two_year_recid==1\n",
    "\n",
    "print(\"Everyone\")\n",
    "cm = pd.crosstab(guessed3, actual, rownames=['guessed'], colnames=['actual'])\n",
    "# cm\n",
    "print_ppv_fpv(cm)\n",
    "#  - just white defendants\n",
    "print(\"White defendents\")\n",
    "white_def = cv.race == 'Caucasian'\n",
    "print_metrics(guessed3[white_def], actual[white_def])\n",
    "#  - just black defendants\n",
    "print(\"Black defendents\")\n",
    "black_def = cv.race == 'African-American'\n",
    "print_metrics(guessed3[black_def], actual[black_def])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual   False  True \n",
      "guessed              \n",
      "False     3322   2627\n",
      "True        41    182\n",
      "\n",
      "Everyone\n",
      "Accuracy:  0.5677252106286454\n",
      "PPV:  0.8161434977578476\n",
      "FPR:  0.012191495688373476\n",
      "FNR:  0.9352082591669634\n",
      "\n",
      "White defendents\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     1269    784\n",
      "True        12     38\n",
      "\n",
      "Accuracy:  0.6214931050879696\n",
      "PPV:  0.76\n",
      "FPR:  0.00936768149882904\n",
      "FNR:  0.9537712895377128\n",
      "\n",
      "Black defendents\n",
      "actual   False  True \n",
      "guessed              \n",
      "False     1492   1536\n",
      "True        22    125\n",
      "\n",
      "Accuracy:  0.5092913385826772\n",
      "PPV:  0.8503401360544217\n",
      "FPR:  0.01453104359313078\n",
      "FNR:  0.9247441300421433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = predict_threshold_groups(lr, x, 0.8, 0.88, black_def)\n",
    "# print(y_pred3)\n",
    "\n",
    "guessed3=pd.Series(y_pred3)==1\n",
    "actual=cv.two_year_recid==1\n",
    "cm = pd.crosstab(guessed3, actual, rownames=['guessed'], colnames=['actual'])\n",
    "print(cm)\n",
    "print()\n",
    "print(\"Everyone\")\n",
    "print_ppv_fpv(cm)\n",
    "#  - just white defendants\n",
    "print(\"White defendents\")\n",
    "white_def = cv.race == 'Caucasian'\n",
    "print_metrics(guessed3[white_def], actual[white_def])\n",
    "#  - just black defendants\n",
    "print(\"Black defendents\")\n",
    "black_def = cv.race == 'African-American'\n",
    "print_metrics(guessed3[black_def], actual[black_def])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the thresholds so the False Positive Rate is the same for white and black defendants.\n",
    "- What did you change to achive this?\n",
    "- What effect does this have on the overall accuracy, FPR, FNR, and PPV?\n",
    "- What effect does this have on the PPV for white and black?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changes made:**\n",
    "\n",
    "I experimented with changing both the thresholds:\n",
    " - thresold A: since this is the threshold for Caucasian males, it gives a lower FPR. I tried to lower the threshold so that the FPR would increase to that of African Americans. This occurs for a threshold = 0.41 where FPR = 0.301, which is the closest I could get to FPR = 0.330 of African Americans\n",
    " - threshold B: I tried to increase the threshold here, to reduce the FPR for African Americans. The closest I can get to is: for threshold = 0.587, the FPR = 0.178, whiCausch is close to FPR for Caucasians at 0.171"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall Accuracy, FPR, FNR, PPV:**\n",
    "\n",
    "The overall accuracy would decrease if either of the thresholds were changed. However, it dropped lower for when threshold B was changed (0.649 vs. 0.658), but the difference may not be significant.\n",
    "\n",
    "The overall FPR reduces when threshold B is changed - this makes sense as changing the threshold for African Americans is done to reduce their FPR. On the other hand, playing with threshold A increases the overall FPR for the same reasons. I'm pretty certain that the FPR will be equal at other values of the thresholds, but I am choosing to ignore the question of where we should set the threshold (and hence, define bias) for this assignment.\n",
    "\n",
    "Since FNR is inversely proportional to FPR, it is obvious that FNR increases when I try to reduce the FPR for African Americans, and decreases when I increase the FPR for Caucasians. This raises interesting questions about the consequences we are willing to pay to achieve equality - and which kind of equality. Should FPR be increased for both races so that the FNR remain low, or would you rather have FPRs low and deal with FNR?\n",
    "\n",
    "PPV for the overall system increases when threshold B is increased (honestly, I'm a little surprised). This could be one of the indicators for choosing which thresholds should be changed. If overall precision of a system increases, that could be one of the ways to justify parameter decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PPV effect on Caucasians and African Americans:**\n",
    "\n",
    "Again, PPV seems to be directly proportional to the threshold. A higher threshold increases PPV for African Americans, and a lower threshold for Caucasians decreases it. On the other hand, increasing both thresholds indiscriminately while keeping FPR equal will increase PPV for both races as well as overall, but as a result, FNR also increases highly, which is an interesting trade-off to keep in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     261\n",
       "2     175\n",
       "3     140\n",
       "5     127\n",
       "4     123\n",
       "6     114\n",
       "7      84\n",
       "8      56\n",
       "9      53\n",
       "10     42\n",
       "Name: decile_score, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv[cv.sex == 'Female'][decile_col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Predicting race and the impossibility of blinding\n",
    "So far we've excluded race as a predictive variable, hoping that this would make the results unbiased. But is race encoded in the other data points? To find out, alter the regression above to try to predict race from the other demographic and criminal history variables.\n",
    "\n",
    "How accurately can you predict race just on these factors alone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use cross validation and the classifier of your choice to see how well you can predict race\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this accuracy to just guessing one race all the time. Which race is more common in this data and what would the accuracy be if we just always guessed that race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is the most common race in our arrest data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is the accuracy if we always guess the most common race?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, how much information about race \"leaks\" into our original recidivism predictor, even if we don't give it the race variable as a feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(your answer here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
